<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Cookbook &raquo; GPU Tasking (cudaFlow) | Taskflow QuickStart</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400i,600,600i%7CSource+Code+Pro:400,400i,600" />
  <link rel="stylesheet" href="m-dark+documentation.compiled.css" />
  <link rel="icon" href="favicon.ico" type="image/vnd.microsoft.icon" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#22272e" />
</head>
<body>
<header><nav id="navigation">
  <div class="m-container">
    <div class="m-row">
      <span id="m-navbar-brand" class="m-col-t-8 m-col-m-none m-left-m">
        <a href="https://taskflow.github.io"><img src="taskflow_logo.png" alt="" />Taskflow</a> <span class="m-breadcrumb">|</span> <a href="index.html" class="m-thin">QuickStart</a>
      </span>
      <div class="m-col-t-4 m-hide-m m-text-right m-nopadr">
        <a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
          <path id="m-doc-search-icon-path" d="m6 0c-3.31 0-6 2.69-6 6 0 3.31 2.69 6 6 6 1.49 0 2.85-0.541 3.89-1.44-0.0164 0.338 0.147 0.759 0.5 1.15l3.22 3.79c0.552 0.614 1.45 0.665 2 0.115 0.55-0.55 0.499-1.45-0.115-2l-3.79-3.22c-0.392-0.353-0.812-0.515-1.15-0.5 0.895-1.05 1.44-2.41 1.44-3.89 0-3.31-2.69-6-6-6zm0 1.56a4.44 4.44 0 0 1 4.44 4.44 4.44 4.44 0 0 1-4.44 4.44 4.44 4.44 0 0 1-4.44-4.44 4.44 4.44 0 0 1 4.44-4.44z"/>
        </svg></a>
        <a id="m-navbar-show" href="#navigation" title="Show navigation"></a>
        <a id="m-navbar-hide" href="#" title="Hide navigation"></a>
      </div>
      <div id="m-navbar-collapse" class="m-col-t-12 m-show-m m-col-m-none m-right-m">
        <div class="m-row">
          <ol class="m-col-t-6 m-col-m-none">
            <li><a href="pages.html">Handbook</a></li>
            <li><a href="namespaces.html">Namespaces</a></li>
          </ol>
          <ol class="m-col-t-6 m-col-m-none" start="3">
            <li><a href="annotated.html">Classes</a></li>
            <li><a href="files.html">Files</a></li>
            <li class="m-show-m"><a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
              <use href="#m-doc-search-icon-path" />
            </svg></a></li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</nav></header>
<main><article>
  <div class="m-container m-container-inflatable">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <h1>
          <span class="m-breadcrumb"><a href="Cookbook.html">Cookbook</a> &raquo;</span>
          GPU Tasking (cudaFlow)
        </h1>
<p>Modern scientific computing typically leverages GPU-powered parallel processing cores to speed up large-scale applications. This chapter discusses how to implement CPU-GPU heterogeneous tasking algorithms with <a href="https://developer.nvidia.com/cuda-zone">Nvidia CUDA</a>.</p><section id="GPUTaskingcudaFlowIncludeTheHeader"><h2><a href="#GPUTaskingcudaFlowIncludeTheHeader">Include the Header</a></h2><p>You need to include the header file, <code>taskflow/cuda/cudaflow.hpp</code>, for creating a <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a> task.</p></section><section id="Create_a_cudaFlow"><h2><a href="#Create_a_cudaFlow">Create a cudaFlow</a></h2><p>Taskflow leverages <a href="https://developer.nvidia.com/blog/cuda-graphs/">CUDA Graph</a> to enable concurrent CPU-GPU tasking using a task graph model, <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a>. A cudaFlow is a task in a taskflow and is associated with a CUDA graph to execute multiple dependent GPU operations in a single CPU call. To create a cudaFlow task, emplace a callable with an argument of type <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a>. The following example implements the canonical saxpy (A·X Plus Y) task graph using <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a>.</p><pre class="m-code"><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="err">#</span><span class="n">include</span><span class="w"> </span><span class="o">&lt;</span><span class="n">taskflow</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="n">cudaflow</span><span class="p">.</span><span class="n">hpp</span><span class="o">&gt;</span><span class="w"></span>
<span class="w"> </span><span class="mi">2</span><span class="o">:</span><span class="w"> </span>
<span class="w"> </span><span class="mi">3</span><span class="o">:</span><span class="w"> </span><span class="c1">// saxpy (single-precision A·X Plus Y) kernel</span>
<span class="w"> </span><span class="mi">4</span><span class="o">:</span><span class="w"> </span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">saxpy</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w"> </span><span class="mi">5</span><span class="o">:</span><span class="w">   </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"></span>
<span class="w"> </span><span class="mi">6</span><span class="o">:</span><span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w"> </span><span class="mi">7</span><span class="o">:</span><span class="w">     </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"></span>
<span class="w"> </span><span class="mi">8</span><span class="o">:</span><span class="w">   </span><span class="p">}</span><span class="w"></span>
<span class="w"> </span><span class="mi">9</span><span class="o">:</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="mi">10</span><span class="o">:</span><span class="w"></span>
<span class="mi">11</span><span class="o">:</span><span class="w"> </span><span class="c1">// main function begins</span>
<span class="mi">12</span><span class="o">:</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="mi">13</span><span class="o">:</span><span class="w"></span>
<span class="mi">14</span><span class="o">:</span><span class="w">   </span><span class="n">tf</span><span class="o">::</span><span class="n">Taskflow</span><span class="w"> </span><span class="n">taskflow</span><span class="p">;</span><span class="w"></span>
<span class="mi">15</span><span class="o">:</span><span class="w">   </span><span class="n">tf</span><span class="o">::</span><span class="n">Executor</span><span class="w"> </span><span class="n">executor</span><span class="p">;</span><span class="w"></span>
<span class="mi">16</span><span class="o">:</span><span class="w">  </span>
<span class="mi">17</span><span class="o">:</span><span class="w">   </span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">&lt;&lt;</span><span class="mi">20</span><span class="p">;</span><span class="w">                            </span><span class="c1">// size of the vector</span>
<span class="mi">18</span><span class="o">:</span><span class="w"></span>
<span class="mi">19</span><span class="o">:</span><span class="w">   </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hx</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">);</span><span class="w">                      </span><span class="c1">// x vector at host</span>
<span class="mi">20</span><span class="o">:</span><span class="w">   </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hy</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">);</span><span class="w">                      </span><span class="c1">// y vector at host</span>
<span class="mi">21</span><span class="o">:</span><span class="w"></span>
<span class="mi">22</span><span class="o">:</span><span class="w">   </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">dx</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span><span class="w">                                  </span><span class="c1">// x vector at device</span>
<span class="mi">23</span><span class="o">:</span><span class="w">   </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">dy</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span><span class="w">                                  </span><span class="c1">// y vector at device</span>
<span class="mi">24</span><span class="o">:</span><span class="w">  </span>
<span class="mi">25</span><span class="o">:</span><span class="w">   </span><span class="n">tf</span><span class="o">::</span><span class="n">Task</span><span class="w"> </span><span class="n">allocate_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">(</span><span class="w"></span>
<span class="mi">26</span><span class="o">:</span><span class="w">     </span><span class="p">[</span><span class="o">&amp;</span><span class="p">](){</span><span class="w"> </span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));}</span><span class="w"></span>
<span class="mi">27</span><span class="o">:</span><span class="w">   </span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;allocate_x&quot;</span><span class="p">);</span><span class="w"></span>
<span class="mi">28</span><span class="o">:</span><span class="w"></span>
<span class="mi">29</span><span class="o">:</span><span class="w">   </span><span class="n">tf</span><span class="o">::</span><span class="n">Task</span><span class="w"> </span><span class="n">allocate_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">(</span><span class="w"></span>
<span class="mi">30</span><span class="o">:</span><span class="w">     </span><span class="p">[</span><span class="o">&amp;</span><span class="p">](){</span><span class="w"> </span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));}</span><span class="w"></span>
<span class="mi">31</span><span class="o">:</span><span class="w">   </span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;allocate_y&quot;</span><span class="p">);</span><span class="w"></span>
<span class="mi">32</span><span class="o">:</span><span class="w"></span>
<span class="mi">33</span><span class="o">:</span><span class="w">   </span><span class="n">tf</span><span class="o">::</span><span class="n">Task</span><span class="w"> </span><span class="n">cudaflow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="mi">34</span><span class="o">:</span><span class="w">     </span><span class="c1">// create data transfer tasks</span>
<span class="mi">35</span><span class="o">:</span><span class="w">     </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">h2d_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_x&quot;</span><span class="p">);</span><span class="w"> </span>
<span class="mi">36</span><span class="o">:</span><span class="w">     </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">h2d_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_y&quot;</span><span class="p">);</span><span class="w"></span>
<span class="mi">37</span><span class="o">:</span><span class="w">     </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">d2h_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_x&quot;</span><span class="p">);</span><span class="w"></span>
<span class="mi">38</span><span class="o">:</span><span class="w">     </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">d2h_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_y&quot;</span><span class="p">);</span><span class="w"></span>
<span class="mi">39</span><span class="o">:</span><span class="w"></span>
<span class="mi">40</span><span class="o">:</span><span class="w">     </span><span class="c1">// launch saxpy&lt;&lt;&lt;(N+255)/256, 256, 0&gt;&gt;&gt;(N, 2.0f, dx, dy)</span>
<span class="mi">41</span><span class="o">:</span><span class="w">     </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">(</span><span class="w"></span>
<span class="mi">42</span><span class="o">:</span><span class="w">       </span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">saxpy</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">dy</span><span class="w"></span>
<span class="mi">43</span><span class="o">:</span><span class="w">     </span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span><span class="w"></span>
<span class="mi">44</span><span class="o">:</span><span class="w"></span>
<span class="mi">45</span><span class="o">:</span><span class="w">     </span><span class="n">kernel</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">h2d_x</span><span class="p">,</span><span class="w"> </span><span class="n">h2d_y</span><span class="p">)</span><span class="w"></span>
<span class="mi">46</span><span class="o">:</span><span class="w">           </span><span class="p">.</span><span class="n">precede</span><span class="p">(</span><span class="n">d2h_x</span><span class="p">,</span><span class="w"> </span><span class="n">d2h_y</span><span class="p">);</span><span class="w"></span>
<span class="mi">48</span><span class="o">:</span><span class="w">   </span><span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span><span class="w"></span>
<span class="mi">49</span><span class="o">:</span><span class="w">   </span><span class="n">cudaflow</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">allocate_x</span><span class="p">,</span><span class="w"> </span><span class="n">allocate_y</span><span class="p">);</span><span class="w">  </span><span class="c1">// overlap memory alloc</span>
<span class="mi">50</span><span class="o">:</span><span class="w">  </span>
<span class="mi">51</span><span class="o">:</span><span class="w">   </span><span class="n">executor</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">taskflow</span><span class="p">).</span><span class="n">wait</span><span class="p">();</span><span class="w"></span>
<span class="mi">52</span><span class="o">:</span><span class="w"></span>
<span class="mi">53</span><span class="o">:</span><span class="w">   </span><span class="n">taskflow</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="p">);</span><span class="w">                  </span><span class="c1">// dump the taskflow</span>
<span class="mi">54</span><span class="o">:</span><span class="w"> </span><span class="p">}</span><span class="w"></span></pre><div class="m-graph"><svg style="width: 30.438rem; height: 14.562rem;" viewBox="0.00 0.00 486.62 232.77">
<g transform="scale(1 1) rotate(0) translate(4 228.77)">
<title>Taskflow</title>
<g id="clust1" class="cluster"><title>cluster_p0x55b2191178a8</title>
<polygon points="8,-47.3848 8,-180.385 470.617,-180.385 470.617,-47.3848 8,-47.3848"/>
<text text-anchor="middle" x="239.309" y="-163.585">cudaFlow: saxpy</text>
</g>
<g id="node1" class="node"><title>p0x55b219117698</title>
<ellipse cx="301.149" cy="-206.385" rx="66.4361" ry="18.2703"/>
<text text-anchor="middle" x="301.149" y="-202.585">allocate_x</text>
</g>
<g id="node2" class="node"><title>p0x55b2191178a8</title>
<polygon points="462.617,-118.385 459.617,-122.385 438.617,-122.385 435.617,-118.385 403.617,-118.385 403.617,-82.3848 462.617,-82.3848 462.617,-118.385"/>
<text text-anchor="middle" x="433.117" y="-96.5848">saxpy</text>
</g>
<g id="edge1" class="edge"><title>p0x55b219117698&#45;&gt;p0x55b2191178a8</title>
<path fill="none" stroke="black" d="M350.265,-193.936C356.388,-191.301 362.348,-188.147 367.617,-184.385 388.483,-169.486 405.754,-145.896 417.156,-127.503"/>
<polygon points="420.296,-129.072 422.422,-118.692 414.287,-125.481 420.296,-129.072"/>
</g>
<g id="node3" class="node"><title>p0x55b2191177a0</title>
<ellipse cx="301.149" cy="-18.3848" rx="66.4361" ry="18.2703"/>
<text text-anchor="middle" x="301.149" y="-14.5848">allocate_y</text>
</g>
<g id="edge2" class="edge"><title>p0x55b2191177a0&#45;&gt;p0x55b2191178a8</title>
<path fill="none" stroke="black" d="M345.108,-32.2422C352.836,-35.4401 360.644,-39.164 367.617,-43.3848 382.056,-52.1236 396.308,-64.2455 407.729,-75.0648"/>
<polygon points="405.543,-77.8218 415.15,-82.2893 410.426,-72.806 405.543,-77.8218"/>
</g>
<g id="node4" class="node"><title>p0x7f2870401a50</title>
<ellipse cx="59.8406" cy="-128.385" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="59.8406" y="-124.585">h2d_x</text>
</g>
<g id="node5" class="node"><title>p0x7f2870402bc0</title>
<polygon points="198.681,-118.385 143.681,-118.385 139.681,-114.385 139.681,-82.3848 194.681,-82.3848 198.681,-86.3848 198.681,-118.385"/>
<polyline points="194.681,-114.385 139.681,-114.385 "/>
<polyline points="194.681,-114.385 194.681,-82.3848 "/>
<polyline points="194.681,-114.385 198.681,-118.385 "/>
<text text-anchor="middle" x="169.181" y="-96.5848">saxpy</text>
</g>
<g id="edge3" class="edge"><title>p0x7f2870401a50&#45;&gt;p0x7f2870402bc0</title>
<path fill="none" stroke="black" d="M97.481,-118.827C107.883,-116.114 119.236,-113.152 129.741,-110.412"/>
<polygon points="130.701,-113.779 139.494,-107.868 128.934,-107.005 130.701,-113.779"/>
</g>
<g id="node7" class="node"><title>p0x7f2870402310</title>
<ellipse cx="301.149" cy="-73.3848" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="301.149" y="-69.5848">d2h_x</text>
</g>
<g id="edge7" class="edge"><title>p0x7f2870402bc0&#45;&gt;p0x7f2870402310</title>
<path fill="none" stroke="black" d="M198.703,-94.4595C214.069,-91.2673 233.457,-87.2397 251.157,-83.5626"/>
<polygon points="252.261,-86.908 261.34,-81.4471 250.837,-80.0543 252.261,-86.908"/>
</g>
<g id="node8" class="node"><title>p0x7f2870402780</title>
<ellipse cx="301.149" cy="-128.385" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="301.149" y="-124.585">d2h_y</text>
</g>
<g id="edge8" class="edge"><title>p0x7f2870402bc0&#45;&gt;p0x7f2870402780</title>
<path fill="none" stroke="black" d="M198.703,-106.529C214.194,-109.867 233.773,-114.085 251.588,-117.923"/>
<polygon points="251.317,-121.445 261.83,-120.129 252.792,-114.602 251.317,-121.445"/>
</g>
<g id="node6" class="node"><title>p0x7f2870401eb0</title>
<ellipse cx="59.8406" cy="-73.3848" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="59.8406" y="-69.5848">h2d_y</text>
</g>
<g id="edge4" class="edge"><title>p0x7f2870401eb0&#45;&gt;p0x7f2870402bc0</title>
<path fill="none" stroke="black" d="M97.7812,-82.6766C108.167,-85.2892 119.482,-88.1353 129.943,-90.7664"/>
<polygon points="129.1,-94.1634 139.652,-93.2085 130.807,-87.3748 129.1,-94.1634"/>
</g>
<g id="edge5" class="edge"><title>p0x7f2870402310&#45;&gt;p0x55b2191178a8</title>
<path fill="none" stroke="black" d="M340.792,-81.4126C357.399,-84.8625 376.768,-88.8864 393.385,-92.3384"/>
<polygon points="392.823,-95.7963 403.326,-94.4036 394.247,-88.9427 392.823,-95.7963"/>
</g>
<g id="edge6" class="edge"><title>p0x7f2870402780&#45;&gt;p0x55b2191178a8</title>
<path fill="none" stroke="black" d="M340.441,-120.135C357.183,-116.528 376.786,-112.305 393.559,-108.692"/>
<polygon points="394.547,-112.059 403.585,-106.532 393.072,-105.216 394.547,-112.059"/>
</g>
</g>
</svg>
</div><p>Debrief:</p><ul><li>Lines 3-9 define a saxpy kernel using CUDA</li><li>Lines 19-20 declare two host vectors, <code>hx</code> and <code>hy</code></li><li>Lines 22-23 declare two device vector pointers, <code>dx</code> and <code>dy</code></li><li>Lines 25-31 declare two tasks to allocate memory for <code>dx</code> and <code>dy</code> on device, each of <code>N*sizeof(float)</code> bytes</li><li>Lines 33-48 create a cudaFlow to define a GPU task graph that contains:<ul><li>two host-to-device data transfer tasks</li><li>one saxpy kernel task</li><li>two device-to-host data transfer tasks</li></ul></li><li>Lines 49-53 define the task dependency between host tasks and the cudaFlow tasks and execute the taskflow</li></ul>
<p><a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a> is a lightweight abstraction over CUDA Graph. We do not expend yet another effort on simplifying kernel programming but focus on tasking CUDA operations and their dependencies. This organization lets users fully take advantage of CUDA featuress that are commensurate with their domain knowledge, while leaving difficult task parallelism details to Taskflow.</p></section><section id="Compile_a_cudaFlow_program"><h2><a href="#Compile_a_cudaFlow_program">Compile a cudaFlow Program</a></h2><p>Use <a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvcc</a> to compile a cudaFlow program:</p><pre class="m-code"><span class="o">~</span><span class="n">$</span><span class="w"> </span><span class="n">nvcc</span><span class="w"> </span><span class="o">-</span><span class="n">std</span><span class="o">=</span><span class="n">c</span><span class="o">++</span><span class="mi">17</span><span class="w"> </span><span class="n">my_cudaflow</span><span class="p">.</span><span class="n">cu</span><span class="w"> </span><span class="o">-</span><span class="n">I</span><span class="w"> </span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">include</span><span class="o">/</span><span class="n">taskflow</span><span class="w"> </span><span class="o">-</span><span class="n">O2</span><span class="w"> </span><span class="o">-</span><span class="n">o</span><span class="w"> </span><span class="n">my_cudaflow</span><span class="w"></span>
<span class="o">~</span><span class="n">$</span><span class="w"> </span><span class="p">.</span><span class="o">/</span><span class="n">my_cudaflow</span><span class="w"></span></pre><p>Please visit the page <a href="CompileTaskflowWithCUDA.html" class="m-doc">Compile Taskflow with CUDA</a> for more details.</p></section><section id="run_a_cudaflow_on_a_specific_gpu"><h2><a href="#run_a_cudaflow_on_a_specific_gpu">Run a cudaFlow on Specific GPU</a></h2><p>By default, a cudaFlow runs on the current CUDA GPU associated with the caller, which is typically GPU <code>0</code>. Each CUDA GPU has an integer identifier in the range of <code>[0, N)</code>, where <code>N</code> is the number of CUDA GPUs in a system. You can run a <a href="classtf_1_1cudaFlow.html" class="m-doc">cudaFlow</a> on a specific GPU using <a href="classtf_1_1FlowBuilder.html#afdf47fd1a358fb64f8c1b89e2a393169" class="m-doc">tf::<wbr />Taskflow::<wbr />emplace_on</a>. The code below creates a <a href="classtf_1_1cudaFlow.html" class="m-doc">cudaFlow</a> that runs on GPU <code>2</code>.</p><pre class="m-code"><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace_on</span><span class="p">([]</span><span class="w"> </span><span class="p">(</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cudaflow</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="c1">// here, cudaflow is under GPU 2</span>
<span class="w">  </span><span class="c1">// ...</span>
<span class="p">},</span><span class="w"> </span><span class="mi">2</span><span class="p">);</span><span class="w">  </span><span class="c1">// place the cudaFlow on GPU 2</span></pre><aside class="m-note m-warning"><h4>Attention</h4><p><a href="classtf_1_1FlowBuilder.html#afdf47fd1a358fb64f8c1b89e2a393169" class="m-doc">tf::<wbr />Taskflow::<wbr />emplace_on</a> allows you to place a cudaFlow on a particular GPU device, but it is your responsibility to ensure correct memory access. For example, you may not allocate a memory block on GPU <code>2</code> while accessing it from a kernel on GPU <code>0</code>.</p></aside><p>An easy practice is to allocate <em>unified shared memory</em> using <code>cudaMallocManaged</code> and let the CUDA runtime perform automatic memory migration between GPUs.</p></section><section id="GPUMemoryOperations"><h2><a href="#GPUMemoryOperations">Create Memory Operation Tasks</a></h2><p><a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a> provides a set of methods for users to manipulate device memory. There are two categories, <em>raw</em> data and <em>typed</em> data. Raw data operations are methods with prefix <code>mem</code>, such as <code>memcpy</code> and <code>memset</code>, that operate in <em>bytes</em>. Typed data operations such as <code>copy</code>, <code>fill</code>, and <code>zero</code>, take <em>logical count</em> of elements. For instance, the following three methods have the same result of zeroing <code>sizeof(int)*count</code> bytes of the device memory area pointed to by <code>target</code>.</p><pre class="m-code"><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">target</span><span class="p">;</span><span class="w"></span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span><span class="w"></span>
<span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">){</span><span class="w"></span>
<span class="w">  </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">memset_target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">memset</span><span class="p">(</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">count</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">same_as_above</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">fill</span><span class="p">(</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">same_as_above_again</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">zero</span><span class="p">(</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">);</span><span class="w"></span>
<span class="p">});</span><span class="w"></span></pre><p>The method <a href="classtf_1_1cudaFlow.html#a21d4447bc834f4d3e1bb4772c850d090" class="m-doc">cudaFlow::<wbr />fill</a> is a more powerful version of <a href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2" class="m-doc">cudaFlow::<wbr />memset</a>. It can fill a memory area with any value of type <code>T</code>, given that <code>sizeof(T)</code> is 1, 2, or 4 bytes. For example, the following code sets each element in the array <code>target</code> to 1234.</p><pre class="m-code"><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">){</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">fill</span><span class="p">(</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="mi">1234</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">);</span><span class="w"> </span><span class="p">});</span><span class="w"></span></pre><p>Similar concept applies to <a href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559" class="m-doc">cudaFlow::<wbr />memcpy</a> and <a href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f" class="m-doc">cudaFlow::<wbr />copy</a> as well.</p><pre class="m-code"><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">){</span><span class="w"></span>
<span class="w">  </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">memcpy_target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">memcpy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">count</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">same_as_above</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">);</span><span class="w"></span>
<span class="p">});</span><span class="w"></span></pre></section><section id="StudyThecudaFlowGranularity"><h2><a href="#StudyThecudaFlowGranularity">Study the Granularity</a></h2><p>Creating a cudaFlow has certain overhead, which means <em>fine-grained</em> tasking such as one GPU operation per cudaFlow may not give you any performance gain. You should aggregate as many GPU operations as possible in a cudaFlow to launch the entire graph once instead of separated graphs. For example, the following code creates a fine-grained saxpy task graph using one cudaFlow per GPU operation.</p><pre class="m-code"><span class="n">tf</span><span class="o">::</span><span class="n">Task</span><span class="w"> </span><span class="n">h2d_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_x&quot;</span><span class="p">);</span><span class="w"></span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_x&quot;</span><span class="p">);</span><span class="w">  </span><span class="c1">// creates the 1st cudaFlow</span>

<span class="n">tf</span><span class="o">::</span><span class="n">Task</span><span class="w"> </span><span class="n">h2d_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_y&quot;</span><span class="p">);</span><span class="w"></span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_y&quot;</span><span class="p">);</span><span class="w">  </span><span class="c1">// creates the 2nd cudaFlow </span>

<span class="n">tf</span><span class="o">::</span><span class="n">Task</span><span class="w"> </span><span class="n">d2h_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_x&quot;</span><span class="p">);</span><span class="w"></span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_x&quot;</span><span class="p">);</span><span class="w">  </span><span class="c1">// creates the 3rd cudaFlow</span>

<span class="n">tf</span><span class="o">::</span><span class="n">Task</span><span class="w"> </span><span class="n">d2h_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_y&quot;</span><span class="p">);</span><span class="w"></span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_y&quot;</span><span class="p">);</span><span class="w">  </span><span class="c1">// creates the 4th cudaFlow</span>

<span class="n">tf</span><span class="o">::</span><span class="n">Task</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">saxpy</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">dy</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span><span class="w"></span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;kernel&quot;</span><span class="p">);</span><span class="w"> </span><span class="c1">// creates the 5th cudaFlow</span>

<span class="n">kernel</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">h2d_x</span><span class="p">,</span><span class="w"> </span><span class="n">h2d_y</span><span class="p">)</span><span class="w"></span>
<span class="w">      </span><span class="p">.</span><span class="n">precede</span><span class="p">(</span><span class="n">d2h_x</span><span class="p">,</span><span class="w"> </span><span class="n">d2h_y</span><span class="p">);</span><span class="w"></span></pre><div class="m-graph"><svg style="width: 38.875rem; height: 21.250rem;" viewBox="0.00 0.00 622.00 339.54">
<g transform="scale(1 1) rotate(0) translate(4 335.539)">
<title>Taskflow</title>
<g id="clust1" class="cluster"><title>cluster_p0x21987b0</title>
<polygon points="463,-166.77 463,-323.539 606,-323.539 606,-166.77 463,-166.77"/>
<text text-anchor="middle" x="534.5" y="-306.739">cudaFlow: h2d_x</text>
</g>
<g id="clust2" class="cluster"><title>cluster_p0x2198870</title>
<polygon points="312,-166.77 312,-323.539 455,-323.539 455,-166.77 312,-166.77"/>
<text text-anchor="middle" x="383.5" y="-306.739">cudaFlow: h2d_y</text>
</g>
<g id="clust3" class="cluster"><title>cluster_p0x2198930</title>
<polygon points="8,-8 8,-158.77 151,-158.77 151,-8 8,-8"/>
<text text-anchor="middle" x="79.5" y="-141.97">cudaFlow: d2h_x</text>
</g>
<g id="clust4" class="cluster"><title>cluster_p0x21989f0</title>
<polygon points="312,-8 312,-158.77 455,-158.77 455,-8 312,-8"/>
<text text-anchor="middle" x="383.5" y="-141.97">cudaFlow: d2h_y</text>
</g>
<g id="clust5" class="cluster"><title>cluster_p0x2198ab0</title>
<polygon points="159,-80.3848 159,-244.77 304,-244.77 304,-80.3848 159,-80.3848"/>
<text text-anchor="middle" x="231.5" y="-227.97">cudaFlow: kernel</text>
</g>
<g id="node1" class="node"><title>p0x21987b0</title>
<polygon points="539,-210.77 536,-214.77 515,-214.77 512,-210.77 477,-210.77 477,-174.77 539,-174.77 539,-210.77"/>
<text text-anchor="middle" x="508" y="-188.97">h2d_x</text>
</g>
<g id="node2" class="node"><title>p0x2198ab0</title>
<polygon points="296,-124.385 293,-128.385 272,-128.385 269,-124.385 232,-124.385 232,-88.3848 296,-88.3848 296,-124.385"/>
<text text-anchor="middle" x="264" y="-102.585">kernel</text>
</g>
<g id="edge1" class="edge"><title>p0x21987b0&#45;&gt;p0x2198ab0</title>
<path fill="none" stroke="black" d="M479.527,-174.735C472.988,-171.542 465.918,-168.627 459,-166.77 426.547,-158.055 338.142,-173.621 308,-158.77 296.429,-153.069 286.688,-142.802 279.337,-132.936"/>
<polygon points="282.068,-130.732 273.505,-124.494 276.309,-134.711 282.068,-130.732"/>
</g>
<g id="node6" class="node"><title>p0x2198930</title>
<polygon points="136,-52 133,-56 112,-56 109,-52 74,-52 74,-16 136,-16 136,-52"/>
<text text-anchor="middle" x="105" y="-30.2">d2h_x</text>
</g>
<g id="edge7" class="edge"><title>p0x2198ab0&#45;&gt;p0x2198930</title>
<path fill="none" stroke="black" d="M231.824,-91.1414C206.932,-80.1224 172.308,-64.7955 145.526,-52.9397"/>
<polygon points="146.607,-49.5907 136.046,-48.7432 143.773,-55.9916 146.607,-49.5907"/>
</g>
<g id="node8" class="node"><title>p0x21989f0</title>
<polygon points="388,-52 385,-56 364,-56 361,-52 326,-52 326,-16 388,-16 388,-52"/>
<text text-anchor="middle" x="357" y="-30.2">d2h_y</text>
</g>
<g id="edge8" class="edge"><title>p0x2198ab0&#45;&gt;p0x21989f0</title>
<path fill="none" stroke="black" d="M286.513,-88.3466C298.419,-79.3356 313.215,-68.1378 326.172,-58.3315"/>
<polygon points="328.511,-60.9509 334.372,-52.1252 324.286,-55.3692 328.511,-60.9509"/>
</g>
<g id="node3" class="node"><title>p0x7fe390000e60</title>
<ellipse cx="515" cy="-271.154" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="515" y="-267.354">h2d_x</text>
</g>
<g id="edge2" class="edge"><title>p0x7fe390000e60&#45;&gt;p0x21987b0</title>
<path fill="none" stroke="black" d="M513.376,-252.438C512.525,-243.149 511.464,-231.564 510.509,-221.149"/>
<polygon points="513.965,-220.503 509.567,-210.864 506.994,-221.142 513.965,-220.503"/>
</g>
<g id="node4" class="node"><title>p0x2198870</title>
<polygon points="388,-210.77 385,-214.77 364,-214.77 361,-210.77 326,-210.77 326,-174.77 388,-174.77 388,-210.77"/>
<text text-anchor="middle" x="357" y="-188.97">h2d_y</text>
</g>
<g id="edge3" class="edge"><title>p0x2198870&#45;&gt;p0x2198ab0</title>
<path fill="none" stroke="black" d="M328.821,-174.684C321.742,-169.891 314.357,-164.432 308,-158.77 299.227,-150.955 290.592,-141.402 283.327,-132.662"/>
<polygon points="285.83,-130.191 276.821,-124.615 280.386,-134.592 285.83,-130.191"/>
</g>
<g id="node5" class="node"><title>p0x7fe390001890</title>
<ellipse cx="364" cy="-271.154" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="364" y="-267.354">h2d_y</text>
</g>
<g id="edge4" class="edge"><title>p0x7fe390001890&#45;&gt;p0x2198870</title>
<path fill="none" stroke="black" d="M362.376,-252.438C361.525,-243.149 360.464,-231.564 359.509,-221.149"/>
<polygon points="362.965,-220.503 358.567,-210.864 355.994,-221.142 362.965,-220.503"/>
</g>
<g id="node7" class="node"><title>p0x7fe39000b790</title>
<ellipse cx="99" cy="-106.385" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="99" y="-102.585">d2h_x</text>
</g>
<g id="edge5" class="edge"><title>p0x7fe39000b790&#45;&gt;p0x2198930</title>
<path fill="none" stroke="black" d="M100.483,-87.9863C101.144,-80.23 101.939,-70.9088 102.676,-62.2615"/>
<polygon points="106.172,-62.4595 103.534,-52.1984 99.1971,-61.8649 106.172,-62.4595"/>
</g>
<g id="node9" class="node"><title>p0x7fe3900017e0</title>
<ellipse cx="364" cy="-106.385" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="364" y="-102.585">d2h_y</text>
</g>
<g id="edge6" class="edge"><title>p0x7fe3900017e0&#45;&gt;p0x21989f0</title>
<path fill="none" stroke="black" d="M362.27,-87.9863C361.498,-80.23 360.571,-70.9088 359.711,-62.2615"/>
<polygon points="363.183,-61.8029 358.71,-52.1984 356.217,-62.4957 363.183,-61.8029"/>
</g>
<g id="node10" class="node"><title>p0x7fe390002000</title>
<polygon points="293.5,-210.77 238.5,-210.77 234.5,-206.77 234.5,-174.77 289.5,-174.77 293.5,-178.77 293.5,-210.77"/>
<polyline points="289.5,-206.77 234.5,-206.77 "/>
<polyline points="289.5,-206.77 289.5,-174.77 "/>
<polyline points="289.5,-206.77 293.5,-210.77 "/>
<text text-anchor="middle" x="264" y="-188.97">saxpy</text>
</g>
<g id="edge9" class="edge"><title>p0x7fe390002000&#45;&gt;p0x2198ab0</title>
<path fill="none" stroke="black" d="M264,-174.693C264,-163.255 264,-147.946 264,-134.818"/>
<polygon points="267.5,-134.436 264,-124.436 260.5,-134.436 267.5,-134.436"/>
</g>
</g>
</svg>
</div><p>The following code aggregates the five GPU operations using one cudaFlow to achieve better performance.</p><pre class="m-code"><span class="n">tf</span><span class="o">::</span><span class="n">Task</span><span class="w"> </span><span class="n">cudaflow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">h2d_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_x&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">h2d_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_y&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">d2h_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_x&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">d2h_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_y&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">saxpy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">saxpy</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">dy</span><span class="p">)</span><span class="w"></span>
<span class="w">                         </span><span class="p">.</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">saxpy</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">h2d_x</span><span class="p">,</span><span class="w"> </span><span class="n">h2d_y</span><span class="p">)</span><span class="w"></span>
<span class="w">       </span><span class="p">.</span><span class="n">precede</span><span class="p">(</span><span class="n">d2h_x</span><span class="p">,</span><span class="w"> </span><span class="n">d2h_y</span><span class="p">);</span><span class="w"></span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span><span class="w">  </span><span class="c1">// creates one cudaFlow</span></pre><div class="m-graph"><svg style="width: 19.625rem; height: 6.250rem;" viewBox="0.00 0.00 314.36 99.77">
<g transform="scale(1 1) rotate(0) translate(4 95.7696)">
<title>Taskflow</title>
<g id="node1" class="node"><title>p0x7f2870401a50</title>
<ellipse cx="43.8406" cy="-73.3848" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="43.8406" y="-69.5848">h2d_x</text>
</g>
<g id="node2" class="node"><title>p0x7f2870402bc0</title>
<polygon points="182.681,-63.3848 127.681,-63.3848 123.681,-59.3848 123.681,-27.3848 178.681,-27.3848 182.681,-31.3848 182.681,-63.3848"/>
<polyline points="178.681,-59.3848 123.681,-59.3848 "/>
<polyline points="178.681,-59.3848 178.681,-27.3848 "/>
<polyline points="178.681,-59.3848 182.681,-63.3848 "/>
<text text-anchor="middle" x="153.181" y="-41.5848">saxpy</text>
</g>
<g id="edge1" class="edge"><title>p0x7f2870401a50&#45;&gt;p0x7f2870402bc0</title>
<path fill="none" stroke="black" d="M81.481,-63.8271C91.8826,-61.1138 103.236,-58.1522 113.741,-55.4119"/>
<polygon points="114.701,-58.7787 123.494,-52.8679 112.934,-52.0053 114.701,-58.7787"/>
</g>
<g id="node4" class="node"><title>p0x7f2870402310</title>
<ellipse cx="262.522" cy="-73.3848" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="262.522" y="-69.5848">d2h_x</text>
</g>
<g id="edge3" class="edge"><title>p0x7f2870402bc0&#45;&gt;p0x7f2870402310</title>
<path fill="none" stroke="black" d="M182.947,-52.8883C192.836,-55.468 204.175,-58.4258 215.106,-61.277"/>
<polygon points="214.416,-64.7141 224.975,-63.8515 216.182,-57.9407 214.416,-64.7141"/>
</g>
<g id="node5" class="node"><title>p0x7f2870402780</title>
<ellipse cx="262.522" cy="-18.3848" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="262.522" y="-14.5848">d2h_y</text>
</g>
<g id="edge4" class="edge"><title>p0x7f2870402bc0&#45;&gt;p0x7f2870402780</title>
<path fill="none" stroke="black" d="M182.947,-38.1493C192.741,-35.6856 203.957,-32.8643 214.79,-30.1395"/>
<polygon points="215.735,-33.511 224.579,-27.6772 214.027,-26.7224 215.735,-33.511"/>
</g>
<g id="node3" class="node"><title>p0x7f2870401eb0</title>
<ellipse cx="43.8406" cy="-18.3848" rx="43.6818" ry="18.2703"/>
<text text-anchor="middle" x="43.8406" y="-14.5848">h2d_y</text>
</g>
<g id="edge2" class="edge"><title>p0x7f2870401eb0&#45;&gt;p0x7f2870402bc0</title>
<path fill="none" stroke="black" d="M81.7812,-27.6766C92.1674,-30.2892 103.482,-33.1353 113.943,-35.7664"/>
<polygon points="113.1,-39.1634 123.652,-38.2085 114.807,-32.3748 113.1,-39.1634"/>
</g>
</g>
</svg>
</div><aside class="m-note m-info"><h4>Note</h4><p>We encourage users to understand the parallel structure of their applications to come up with the best granularity of task decomposition. A refined task graph can have significant performance difference from the raw counterpart.</p></aside></section><section id="OffloadAcudaFlow"><h2><a href="#OffloadAcudaFlow">Offload a cudaFlow</a></h2><p>By default, the executor offloads and executes the cudaFlow <em>once</em>, if the cudaFlow is never offloaded from its callable. During the execution, the executor first materializes the cudaFlow by mapping it to a native CUDA graph, creates an executable graph from the native CUDA graph, and then submit the executable graph to the CUDA runtime. Similar to <a href="classtf_1_1Executor.html" class="m-doc">tf::<wbr />Executor</a>, <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a> provides several offload methods to run the GPU task graph:</p><pre class="m-code"><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="c1">// ... create CUDA tasks</span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span><span class="w">      </span><span class="c1">// offload the cudaFlow and run it once</span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">offload_n</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span><span class="w">  </span><span class="c1">// offload the cudaFlow and run it 10 times</span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">offload_until</span><span class="p">([</span><span class="n">repeat</span><span class="o">=</span><span class="mi">5</span><span class="p">]</span><span class="w"> </span><span class="p">()</span><span class="w"> </span><span class="k">mutable</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">repeat</span><span class="o">--</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="p">})</span><span class="w">  </span><span class="c1">// five times</span>
<span class="p">});</span><span class="w"></span></pre><p>After you offload a cudaFlow, it is considered executed, and the executor will <em>not</em> run an offloaded cudaFlow after leaving the cudaFlow task callable. On the other hand, if a cudaFlow is not offloaded, the executor runs it once. For example, the following two versions represent the same execution logic.</p><pre class="m-code"><span class="c1">// version 1: explicitly offload a cudaFlow once</span>
<span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">single_task</span><span class="p">([]</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="p">(){});</span><span class="w"></span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span><span class="w"></span>
<span class="p">});</span><span class="w"></span>

<span class="c1">// version 2 (same as version 1): executor offloads the cudaFlow once</span>
<span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">sf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">cf</span><span class="p">.</span><span class="n">single_task</span><span class="p">([]</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="p">(){});</span><span class="w"></span>
<span class="p">});</span><span class="w"></span></pre></section><section id="UpdateAcudaFlow"><h2><a href="#UpdateAcudaFlow">Update a cudaFlow</a></h2><p>Many GPU applications require you to launch a cudaFlow multiple times and update node parameters (e.g., kernel parameters and memory addresses) between iterations. <a href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444" class="m-doc">tf::<wbr />cudaFlow::<wbr />offload</a> allows you to execute the graph immediately and then update the parameters for the next execution. When you offload a cudaFlow, an executable graph will be created, and you must NOT change the topology but the node parameters between successive executions.</p><pre class="m-code"><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">]</span><span class="w"> </span><span class="p">(</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cf</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="mi">2</span><span class="o">:</span><span class="w">   </span><span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">task</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">grid1</span><span class="p">,</span><span class="w"> </span><span class="n">block1</span><span class="p">,</span><span class="w"> </span><span class="n">shm1</span><span class="p">,</span><span class="w"> </span><span class="n">my_kernel</span><span class="p">,</span><span class="w"> </span><span class="n">args1</span><span class="p">...);</span><span class="w"></span>
<span class="mi">3</span><span class="o">:</span><span class="w">   </span><span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span><span class="w">  </span><span class="c1">// immediately run the cudaFlow once</span>
<span class="mi">4</span><span class="o">:</span><span class="w"></span>
<span class="mi">5</span><span class="o">:</span><span class="w">   </span><span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">task</span><span class="p">,</span><span class="w"> </span><span class="n">grid2</span><span class="p">,</span><span class="w"> </span><span class="n">block2</span><span class="p">,</span><span class="w"> </span><span class="n">shm2</span><span class="p">,</span><span class="w"> </span><span class="n">my_kernel</span><span class="p">,</span><span class="w"> </span><span class="n">args2</span><span class="p">...);</span><span class="w"></span>
<span class="mi">6</span><span class="o">:</span><span class="w">   </span><span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span><span class="w">  </span><span class="c1">// run the cudaFlow again with the same graph topology</span>
<span class="mi">7</span><span class="o">:</span><span class="w">                  </span><span class="c1">// but with different kernel parameters</span>
<span class="mi">8</span><span class="o">:</span><span class="w"> </span><span class="p">});</span><span class="w"></span></pre><p>Debrief:</p><ul><li>Line 2 creates a kernel task to run <code>my_kernel</code> with the given parameters.</li><li>Line 3 offloads the cudaFlow and performs an immediate execution.</li><li>Line 5 updates the parameters of <code>my_kernel</code> through its task.</li><li>Line 6 executes the cudaFlow again with updated kernel parameters.</li></ul><p>Between successive offloads (i.e., executions of a cudaFlow), you can update the task parameters, such as changing the kernel execution parameters and memory operation parameters. However, you must <em>NOT</em> change the topology of an offloaded cudaFlow. Each method of task creation in <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a> has an overload that updates the parameters of the task created from the same creation method.</p><aside class="m-note m-warning"><h4>Attention</h4><p>There are a few restrictions on updating task parameters in a cudaFlow. Notably, you must <em>NOT</em> change the topology of an offloaded graph. In addition, update methods have the following limitations:</p><ul><li>kernel task<ul><li>The kernel function is not allowed to change. This restriction applies to all algorithm tasks that are created using lambda.</li></ul></li><li>memset and memcpy tasks:<ul><li>The CUDA device(s) to which the operand(s) was allocated/mapped cannot change</li><li>The source/destination memory must be allocated from the same contexts as the original source/destination memory.</li></ul></li></ul></aside></section><section id="UsecudaFlowInAStandaloneEnvironment"><h2><a href="#UsecudaFlowInAStandaloneEnvironment">Use cudaFlow in a Standalone Environment</a></h2><p>You can use <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a> in a standalone environment without going through <a href="classtf_1_1Taskflow.html" class="m-doc">tf::<wbr />Taskflow</a> and offloads it to a GPU from the caller thread. All the features we have discussed so far apply to the standalone use. The following code gives an example of using a standalone cudaFlow to create a saxpy task graph that runs on a GPU.</p><pre class="m-code"><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="w"> </span><span class="n">cf</span><span class="p">;</span><span class="w">  </span><span class="c1">// create a standalone cudaFlow</span>

<span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">h2d_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_x&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">h2d_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_y&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">d2h_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_x&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">d2h_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_y&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span><span class="w"> </span><span class="n">saxpy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">saxpy</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">dy</span><span class="p">)</span><span class="w"></span>
<span class="w">                       </span><span class="p">.</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span><span class="w"></span>

<span class="n">saxpy</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">h2d_x</span><span class="p">,</span><span class="w"> </span><span class="n">h2d_y</span><span class="p">)</span><span class="w">   </span><span class="c1">// kernel runs after  host-to-device copy</span>
<span class="w">     </span><span class="p">.</span><span class="n">precede</span><span class="p">(</span><span class="n">d2h_x</span><span class="p">,</span><span class="w"> </span><span class="n">d2h_y</span><span class="p">);</span><span class="w">  </span><span class="c1">// kernel runs before device-to-host copy</span>

<span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span><span class="w">  </span><span class="c1">// offload and run the standalone cudaFlow once</span></pre><p>When using cudaFlow in a standalone environment, it is your choice to decide its GPU context. The following example creates a cudaFlow and executes it on GPU 0.</p><pre class="m-code"><span class="n">tf</span><span class="o">::</span><span class="n">cudaScopedDevice</span><span class="w"> </span><span class="nf">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span><span class="w"></span>
<span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="w"> </span><span class="n">cf</span><span class="p">;</span><span class="w">  </span><span class="c1">// create a standalone cudaFlow on GPU 0</span>
<span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span><span class="w">     </span><span class="c1">// run the capturer once on GPU 0</span></pre><aside class="m-note m-info"><h4>Note</h4><p>In the standalone mode, a written cudaFlow will not be executed untile you explicitly call an offload method, as there is neither a taskflow nor an executor.</p></aside></section>
      </div>
    </div>
  </div>
</article></main>
<div class="m-doc-search" id="search">
  <a href="#!" onclick="return hideSearch()"></a>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-m-8 m-push-m-2">
        <div class="m-doc-search-header m-text m-small">
          <div><span class="m-label m-default">Tab</span> / <span class="m-label m-default">T</span> to search, <span class="m-label m-default">Esc</span> to close</div>
          <div id="search-symbolcount">&hellip;</div>
        </div>
        <div class="m-doc-search-content">
          <form>
            <input type="search" name="q" id="search-input" placeholder="Loading &hellip;" disabled="disabled" autofocus="autofocus" autocomplete="off" spellcheck="false" />
          </form>
          <noscript class="m-text m-danger m-text-center">Unlike everything else in the docs, the search functionality <em>requires</em> JavaScript.</noscript>
          <div id="search-help" class="m-text m-dim m-text-center">
            <p class="m-noindent">Search for symbols, directories, files, pages or
            modules. You can omit any prefix from the symbol or file path; adding a
            <code>:</code> or <code>/</code> suffix lists all members of given symbol or
            directory.</p>
            <p class="m-noindent">Use <span class="m-label m-dim">&darr;</span>
            / <span class="m-label m-dim">&uarr;</span> to navigate through the list,
            <span class="m-label m-dim">Enter</span> to go.
            <span class="m-label m-dim">Tab</span> autocompletes common prefix, you can
            copy a link to the result using <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">L</span> while <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">M</span> produces a Markdown link.</p>
          </div>
          <div id="search-notfound" class="m-text m-warning m-text-center">Sorry, nothing was found.</div>
          <ul id="search-results"></ul>
        </div>
      </div>
    </div>
  </div>
</div>
<script src="search-v2.js"></script>
<script src="searchdata-v2.js" async="async"></script>
<footer><nav>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <p>Taskflow handbook is part of the <a href="https://taskflow.github.io">Taskflow project</a>, copyright © <a href="https://tsung-wei-huang.github.io/">Dr. Tsung-Wei Huang</a>, 2018&ndash;2022.<br />Generated by <a href="https://doxygen.org/">Doxygen</a> 1.8.11 and <a href="https://mcss.mosra.cz/">m.css</a>.</p>
      </div>
    </div>
  </div>
</nav></footer>
</body>
</html>
