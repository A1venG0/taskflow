namespace tf {

/** @page DependentAsyncTasking Asynchronous Tasking with Dependencies

This chapters discusses how to create a task graph dynamically 
using asynchronous tasks,
which is extremely beneficial for workloads that want to
(1) explore task graph parallelism out of dynamic control flow
or 
(2) overlap task graph creation time with individual task execution time.
We recommend that you first read @ref AsyncTasking before this chapter.

@tableofcontents

@section CreateATaskGraphDynamically Create a Task Graph Dynamically

When the construct-and-run model of a task graph is not possible in your application,
you can use tf::Executor::dependent_async and tf::Executor::silent_dependent_async
to create a task graph dynamically.
This type of parallelism is also known as <i>on-the-fly task graph parallelism</i>,
which offers great flexibility for expressing dynamic task parallelism.
The example below dynamically creates a task graph of
four dependent tasks, @c A, @c B, @c C, and @c D, where @c A runs before @c B and @c C
and @c D runs after @c B and @c C:

@dotfile images/simple.dot

@code{.cpp}
tf::Executor executor;
tf::AsyncTask A = executor.silent_dependent_async([](){ printf("A\n"); });
tf::AsyncTask B = executor.silent_dependent_async([](){ printf("B\n"); }, A);
tf::AsyncTask C = executor.silent_dependent_async([](){ printf("C\n"); }, A);
auto [D, fuD] = executor.dependent_async([](){ printf("D\n"); }, B, C);
D.get();  // wait for D to finish, which in turns means A, B, C finish
@endcode

Both tf::Executor::dependent_async and tf::Executor::silent_dependent_async 
create a task of type tf::AsyncTask to run the given function asynchronously.
Additionally, tf::Executor::dependent_async returns a @std_future 
that eventually holds the result of the execution.
When returning from both calls, the executor has scheduled a worker 
to run the task whenever its dependencies are met.
That is, task execution happens @em simultaneously 
with the creation of the task graph, which is different from constructing a %Taskflow
and running it from an executor.


Since this model only allows relating a dependency from the current task 
to a previously created task,
you need a correct topological order of graph expression.
In our example, there are only two possible topological orderings,
either @c ABCD or @c ACBD.
The code below shows another feasible order of expressing this 
dynamic task graph parallelism.

@code{.cpp}
tf::Executor executor;
tf::AsyncTask A = executor.silent_dependent_async([](){ printf("A\n"); });
tf::AsyncTask C = executor.silent_dependent_async([](){ printf("C\n"); }, A);
tf::AsyncTask B = executor.silent_dependent_async([](){ printf("B\n"); }, A);
auto [D, fuD] = executor.dependent_async([](){ printf("D\n"); }, B, C);
D.get();  // wait for D to finish, which in turns means A, B, C finish
@endcode



*/

}


