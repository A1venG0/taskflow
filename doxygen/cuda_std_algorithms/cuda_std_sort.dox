namespace tf {

/** @page CUDASTDSort Parallel Sort

%Taskflow provides standalone template methods for sorting ranges of items
on a CUDA GPU.

@tableofcontents

@section CUDASTDSortItems Sort a Range of Items

tf::cuda_sort performs an in-place parallel sort over a range of elements specified 
by <tt>[first, last)</tt> using the given comparator.
The following code sorts one million random integers in an increasing order on a GPU.

@code{.cpp}
const size_t N = 1000000;
int* vec = tf::cuda_malloc_shared<int>(N);  // vector

// initializes the data
for(size_t i=0; i<N; i++) 
  vec[i] = rand();
} 

// queries the required buffer size to sort a vector
tf::cudaDefaultExecutionPolicy policy;
auto bytes  = tf::cuda_sort_buffer_size<tf::cudaDefaultExecutionPolicy, int>(N);
auto buffer = tf::cuda_malloc_device<std::byte>(bytes);

// sorts the vector
tf::cuda_sort(
  policy, vec, vec+N, [] __device__ (int a, int b) { return a < b; }, buffer
);

// synchronizes the execution and verifies the result
policy.synchronize();
assert(std::is_sorted(vec, vec+N));

// deletes the buffer
tf::cuda_free(buffer);
@endcode

The sort algorithm call runs @em asynchronously through the stream specified
in the execution policy. You need to synchronize the stream to
obtain correct results.
Since the GPU sort algorithm may require extra buffer to store the 
temporary results, you must provide a buffer of size at least the bytes
returned from tf::cuda_sort_buffer_size.

@attention
By default, the 
You must keep the buffer alive before the merge call completes.

*/
}






